# üóìÔ∏è Daily Log ‚Äì 2025-10-31

**Focus:** Building Query Understanding Service Module

## üß† What I Learned

- Zero-shot Classification : Zero-shot text classification is a task in natural language processing where a model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.

- zero-shot classification enables real-time decision-making, as models can quickly generalize to new classes without additional training. This scalability and adaptability make zero-shot classification a powerful tool for developing robust and versatile AI models.

- Natural Language Inference (NLI) is the task of determining the logical relationship between two given sentences: a premise and a hypothesis.The model reads the premise (a statement of fact) and must decide if the hypothesis is true, false, or undetermined based only on the information given in the premise


## üíª Snippet / Command

```py
from transformers import pipeline

pipe = pipeline(model="facebook/bart-large-mnli")
pipe("I have a problem with my iphone that needs to be resolved asap!",
    candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
)
# output
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

‚ö†Ô∏è Speed-Bump / Question

- curl.exe syntax
- Zero-shot vs Few Shot

üîó Links / References

- https://huggingface.co/tasks/zero-shot-classification#:~:text=Zero%2Dshot%20classification%20excludes%20any,feature%20of%20large%20language%20models.

- https://www.researchgate.net/publication/388920473_Challenges_and_Limitations_of_Zero-Shot_and_Few-Shot_Learning_in_Large_Language_Models#:~:text=%E2%80%A2%20Lower%20Accuracy%20Compared%20to,the%20model%20was%20trained%20on.