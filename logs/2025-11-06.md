# üóìÔ∏è Daily Log ‚Äì 2025-11-06

**Focus:** Supervised Learning

## üß† What I Learned

- Supervised Learning: learn from being given "right answers". There are many real world applications, In all of these applications, you would first train your model with examples of inputs X and the right answers, that is, the labels Y. After the model has learned from these input-output or X and Y pairs, it can then take a brand new input X, something it's never seen before.
  - Regression: predict house prices (x,y pairs - infinite possibilities)
  - Classification: Breast cancer detection (true/false/unknown - small, finite, limited categories)
  - there are other, more specialized supervised tasks such as ** Ranking ** 

- For a problem, if you predict a category, it's Classification. If you predict a quantity, it's Regression.
## üíª Snippet / Command

## classification:
```py
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# 1. Load the dataset
# X = features (sepal length, petal width, etc.)
# y = target (the species of flower: 0, 1, or 2)
iris = load_iris()
X, y = iris.data, iris.target

# 2. Split the data (we'll use 80% for training, 20% for testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Create the model
# We're using LogisticRegression, a classic classification algorithm
model = LogisticRegression(max_iter=200)

# 4. Train the model on the training data
model.fit(X_train, y_train)

# 5. Make a prediction on new, unseen data
# Let's take the first flower from our test set
new_flower = X_test[0]
new_flower_actual_species = y_test[0]

# Reshape the data because .predict() expects a 2D array (a batch of samples)
new_flower_reshaped = new_flower.reshape(1, -1)

# The prediction will be a CATEGORY (0, 1, or 2)
prediction = model.predict(new_flower_reshaped)

# Let's see the result
print("--- Classification Demo (Iris Dataset) ---")
print(f"Features for new flower: {new_flower}")
print(f"Model's Prediction:      {prediction[0]}")
print(f"Actual Species:          {new_flower_actual_species}")

# You can see the target names (species)
# print(f"Class '0' is: {iris.target_names[0]}")
# print(f"Class '1' is: {iris.target_names[1]}")
# print(f"Class '2' is: {iris.target_names[2]}")

output:
--- Classification Demo (Iris Dataset) ---
Features for new flower: [6.1 2.8 4.7 1.2]
Model's Prediction:      1
Actual Species:          1
```
## Regression:
```py
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# 1. Load the dataset
# X = features (avg. income, house age, etc.)
# y = target (the median house value, a continuous number)
housing = fetch_california_housing()
X, y = housing.data, housing.target

# 2. Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. Create the model
# We're using LinearRegression, a classic regression algorithm
model = LinearRegression()

# 4. Train the model on the training data
model.fit(X_train, y_train)

# 5. Make a prediction on new, unseen data
# Let's take the first house from our test set
new_house = X_test[0]
new_house_actual_price = y_test[0]

# Reshape the data
new_house_reshaped = new_house.reshape(1, -1)

# The prediction will be a CONTINUOUS VALUE
prediction = model.predict(new_house_reshaped)

# Let's see the result
# Note: The target price is in units of $100,000
print("\n--- Regression Demo (California Housing) ---")
print(f"Features for new house: {new_house.round(2)}")
print(f"Model's Prediction:     ${prediction[0] * 100000:,.2f}")
print(f"Actual Price:           ${new_house_actual_price * 100000:,.2f}")

--- Regression Demo (California Housing) ---
Features for new house: [ 2.33 42.   4.93  1.09 780.   2.31 36.3  -122.1 ]
Model's Prediction:     $119,748.74
Actual Price:           $70,500.00
```

‚ö†Ô∏è Speed-Bump / Question

- 

üîó Links / References

- https://learn.deeplearning.ai/specializations/machine-learning/lesson/iw4mb/supervised-learning-part-2
