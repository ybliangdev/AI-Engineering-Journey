# ğŸ—“ï¸ Daily Log â€“ YYYY-MM-DD

**Focus:** Choosing Embedding Models (for different use cases)

## ğŸ§  What I Learned
- general-purpose retrieval models
- Text Embeddings are vector representations of text that encode semantic information.
- Embedding is not just for text, they can be applied to images, audio, or even graph data. In a general sense, embedding is the process of converting data [of any type] into vectors.


âš ï¸ Speed-Bump / Question
- Why embbeding search seems so fast compare to traditional search?

ğŸ”— Links / References
- https://huggingface.co/spaces/mteb/leaderboard
- https://www.youtube.com/watch?v=6YrkXr-2cCc&t=5s
- https://towardsdev.com/mastering-data-clustering-with-embedding-models-87a228d67405
- https://huggingface.co/blog/mteb
    - https://cloud.google.com/blog/topics/developers-practitioners/find-anything-blazingly-fast-googles-vector-search-technology

- https://huggingface.co/spaces/hesamation/primer-llm-embedding?section=what_are_embeddings?

-https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39
- https://research.netflix.com/