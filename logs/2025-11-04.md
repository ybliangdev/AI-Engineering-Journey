# ğŸ—“ï¸ Daily Log â€“ 2025-11-04

**Focus:** Autoencoders

## ğŸ§  What I Learned

- An autoencoder is a type of artificial neural network used for unsupervised learning.

- Autoencoder's primary goal is to learn a compressed representation (encoding) of the input data.

- The basic idea here is that we have our inputs, and we compress those inputs in such a manner that we have the most important features to reconstruct it back:
  - e.g. Think of it as training a model to summarize a document and then write the original document back out using only the summary.
  - e.g. As a human to draw a tree with the least number of touches, we will draw a line and a couple of branches.
- Denoising autoencoders: Denoising autoencoders are given partially **corrupted input data** and trained to restore the original input by removing useless information through dimensionality reduction.

- Autoencoder Process:

  - Inputs (Original Data): The starting point, which could be an image, text, or any other data format.

  - Compression (Encoding): This is performed by the Encoder network. It maps the input to the low-dimensional representation.

  - Most Important Features (Latent Space/Code): This compressed representation is called the latent space or the bottleneck. Because it's smaller than the input, the network is forced to learn only the most salient featuresâ€”the "essence"â€”needed for successful reconstruction.

  - Reconstruct it Back (Decoding): This is performed by the Decoder network, which takes the compressed features from the latent space and attempts to recreate a version of the original input.

## ğŸ’» Snippet / Command

```py
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
import numpy as np

# --- 1. Define Model Parameters ---
# The size of our compressed (encoded) representation
encoding_dim = 32 
# Input dimension (28x28 pixels = 784)
input_dim = 784 

# --- 2. Build the Autoencoder Architecture ---

# a. Input Layer
input_img = Input(shape=(input_dim,))

# b. Encoder (Compression)
# The input is compressed into the 'encoded' layer (the bottleneck)
encoded = Dense(encoding_dim, activation='relu')(input_img)

# c. Decoder (Reconstruction)
# The compressed 'encoded' layer is reconstructed back to the original input size
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# d. Autoencoder Model
# This model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)

# --- 3. Separate Encoder and Decoder Models (for later use) ---

# Encoder Model (takes input_img, outputs the compressed code)
encoder = Model(input_img, encoded)

# Decoder Model (takes the compressed code, outputs the reconstructed image)
# We use the last layer of the autoencoder
encoded_input = Input(shape=(encoding_dim,))
decoder_layer = autoencoder.layers[-1]
decoder = Model(encoded_input, decoder_layer(encoded_input))

# --- 4. Compile the Model ---
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# --- 5. Prepare Dummy Data (Example Only) ---
# In a real scenario, you'd load and preprocess a dataset like MNIST.
# Let's create a batch of random data for shape purposes (60000 samples of 784 features)
X_train = np.random.rand(60000, input_dim).astype('float32')

# --- 6. Train the Autoencoder ---
# The input (X_train) is the same as the target output (X_train)
print("Starting Training...")
autoencoder.fit(X_train, X_train,
                epochs=5,
                batch_size=256,
                shuffle=True)

# --- 7. Example Usage: Encoding and Decoding ---
test_data = X_train[:10] # Take first 10 samples
compressed_representation = encoder.predict(test_data)
reconstructed_data = decoder.predict(compressed_representation)

print("\nOriginal input shape:", test_data.shape)
print("Compressed (Latent) shape:", compressed_representation.shape)
print("Reconstructed output shape:", reconstructed_data.shape)

output:
Starting Training...
Epoch 1/5
235/235 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4s 10ms/step - loss: 0.6932
Epoch 2/5
235/235 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - loss: 0.6930
Epoch 3/5
235/235 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - loss: 0.6930
Epoch 4/5
235/235 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - loss: 0.6929
Epoch 5/5
235/235 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2s 9ms/step - loss: 0.6929
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 72ms/step
1/1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 70ms/step

Original input shape: (10, 784)
Compressed (Latent) shape: (10, 32)
Reconstructed output shape: (10, 784)
```

âš ï¸ Speed-Bump / Question

- context engineering

ğŸ”— Links / References

- https://www.ibm.com/think/topics/autoencoder#:~:text=Denoising%20autoencoders%20are%20given%20partially,useless%20information%20through%20dimensionality%20reduction.

- https://merveenoyan.medium.com/complete-guide-on-deep-learning-architectures-part-2-autoencoders-293351bbe027

- https://www.youtube.com/watch?v=H1AllrJ-_30&t=3s

Context Engineering Intro
- https://www.youtube.com/watch?v=jLuwLJBQkIs